{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PlayerDetectorTrainer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryanro97/player-detector/blob/master/PlayerDetectorTrainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJrHbtyZ8qXj",
        "colab_type": "text"
      },
      "source": [
        "# Player Detector Trainer\n",
        "---\n",
        "Trainer for frame by frame player detection, using a custom dataset. Implemented using an untrained [PyTorch's Faster R-CNN model with a ResNet-50-FPN Backbone](https://pytorch.org/docs/stable/torchvision/models.html#faster-r-cnn).\n",
        "\n",
        "<br />\n",
        "\n",
        "### Directory Hierarchy:\n",
        "```\n",
        "PlayerDetector\n",
        "├── data\n",
        "    ├── train\n",
        "        ├── images\n",
        "            ├── *.jpg\n",
        "        ├── targets\n",
        "            ├── classes.txt\n",
        "            ├── *.txt\n",
        "    ├── predict\n",
        "        ├── video\n",
        "            ├── *.mp4\n",
        "├── PlayerDetectorTrainer.ipynb\n",
        "├── PlayerDetectorPredictor.ipynb\n",
        "```\n",
        "\n",
        "<br />\n",
        "\n",
        "### Target Labeling\n",
        "Using Tzuta Lin's [LabelImg](https://github.com/tzutalin/labelImg) tool, bounding boxes were hand labeled using the YOLO format.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J3sbAiIGjuS",
        "colab_type": "text"
      },
      "source": [
        "### Install Dependencies for Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpJwvBy58rni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install pillow torch torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58n5kRVO85m3",
        "colab_type": "text"
      },
      "source": [
        "### Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlFq0FwN_aeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGBIhZf6GwLk",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyFXwQ9j_HBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import  Dataset, DataLoader\n",
        "from torchvision.transforms import functional, ToTensor\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx4mbsakGzEL",
        "colab_type": "text"
      },
      "source": [
        "### Custom PyTorch Dataset\n",
        "Handles necessary conversions for YOLO to PyTorch's Faster R-CNN model input format. Also performs augmentation with each image having a 50% probability of being horizontally flipped.\n",
        "\n",
        "<br />\n",
        "\n",
        "#### Errors\n",
        "```\n",
        "IndexError: Image and Target count mismatch\n",
        "TypeError: Image and Target file name mismatch\n",
        "IOError: Target read error\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2biq9E--h5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PlayerTrainerDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        root = os.getcwd()\n",
        "\n",
        "        self.images_dir = os.path.join(root, 'data/train/images')\n",
        "        self.targets_dir = os.path.join(root, 'data/train/targets')\n",
        "\n",
        "        self.images = sorted(os.listdir(self.images_dir))\n",
        "        self.targets = [target for target in \\\n",
        "                        sorted(os.listdir(self.targets_dir)) \\\n",
        "                        if target != 'classes.txt']\n",
        "\n",
        "        if len(self.images) != len(self.targets):\n",
        "            raise IndexError('Image and Target count mismatch')\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self.images_dir, self.images[idx])\n",
        "        target_path = os.path.join(self.targets_dir, self.targets[idx])\n",
        "\n",
        "        image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "        target_name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "\n",
        "        if image_name != target_name:\n",
        "            raise TypeError('Image and Target file name mismatch')\n",
        "        \n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        \n",
        "        target = None\n",
        "        with open(target_path) as f:\n",
        "            target = f.readline().strip().split()\n",
        "        if not target:\n",
        "            raise IOError('Target read error')\n",
        "        \n",
        "        w, h = image.size\n",
        "        \n",
        "        center_x = float(target[1]) * w\n",
        "        center_y = float(target[2]) * h\n",
        "        bbox_w = float(target[3]) * w\n",
        "        bbox_h = float(target[4]) * h\n",
        "        \n",
        "        x0 = round(center_x - (bbox_w / 2))\n",
        "        x1 = round(center_x + (bbox_w / 2))\n",
        "        y0 = round(center_y - (bbox_h / 2))\n",
        "        y1 = round(center_y + (bbox_h / 2))\n",
        "        \n",
        "        boxes = [x0, y0, x1, y1]\n",
        "        labels = torch.as_tensor(1, dtype=torch.int64)\n",
        "\n",
        "        if random.random() < 0.5:\n",
        "            image = functional.hflip(image)\n",
        "            boxes = [w - x1 - 1, y0, w - x0 - 1, y1]\n",
        "\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        image = ToTensor()(image)\n",
        "        \n",
        "        target = [{'boxes': boxes, 'labels': labels}]\n",
        "        \n",
        "        return image, target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t97ua-r2Kn0t",
        "colab_type": "text"
      },
      "source": [
        "### Train Function\n",
        "Takes in the working directory (root directory in the data hierarchy diagram), the number of classes to detect, the learning rate, momentum, and weight decay of the optimizer (using stochastic gradient descent), the number of epochs, and trains the model, then saves the weights in the working directory.\n",
        "\n",
        "<br />\n",
        "\n",
        "#### Parameters\n",
        "```\n",
        "working_dir: String representation of the working directory\n",
        "num_classes: Integer representation of the number of classes to detect\n",
        "opt_lr: Float representation of the optimizers learning rate\n",
        "opt_mom: Float representation of the optimizers momentum\n",
        "opt_wd: Float representation of the optimziers weight decay\n",
        "num_epochs: Integer representation of the number of epochs to train for\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itvWU3I9-pfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(working_dir, num_classes, opt_lr, opt_mom, opt_wd, num_epochs):\n",
        "    os.chdir(working_dir)\n",
        "    \n",
        "    model = fasterrcnn_resnet50_fpn(num_classes=num_classes)\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() \\\n",
        "             else torch.device('cpu')\n",
        "    model.to(device)\n",
        "\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = torch.optim.SGD(params, lr=opt_lr, momentum=opt_mom, \\\n",
        "                                weight_decay=opt_wd)\n",
        "\n",
        "    dataset = PlayerTrainerDataset()\n",
        "    data_loader = DataLoader(dataset, shuffle=True)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, targets in data_loader:\n",
        "            images = list(image.to(device) for image in images)\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "            \n",
        "            loss_dict = model(images, targets)\n",
        "            losses = sum(loss for loss in loss_dict.values())\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            losses.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += losses.item()\n",
        "\n",
        "        print('epoch:%d loss:%.3f' % \\\n",
        "              (epoch + 1, running_loss / len(data_loader)))\n",
        "\n",
        "    torch.save(model.state_dict(), 'weights.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUwW3DUdc29e",
        "colab_type": "text"
      },
      "source": [
        "### Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjl36ow7_BBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_model('/content/drive/My Drive/PlayerDetector', 2, 0.005, 0.9, 0.0005, 25)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}